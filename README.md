# clay-overlord

Clay overlord refers to humans being overlords of AI. "Clay" is often used in the bible to refer to humans.

## Projects

1. langgraph_local_rag_ollam32
    - Local RAG with LangGraph & Ollama (Llama 3.2)

## Useful Links

Interesting libraries & frameworks
- Jan
    - https://github.com/janhq/jan
- RAGFlow
    - https://github.com/infiniflow/ragflow
- Agenta
    - https://github.com/Agenta-AI/agenta

### Interactive Learning
- https://bbycroft.net/llm

### Videos
1. RLHF Reinforcement Learning from Human Feedback
    - https://www.youtube.com/watch?v=vJ4SsfmeQlk
    - Human Feedback -> Reward Model
    - Reward Model -> Reinforcement Learning

### With code
1. Different *agentic system architectures* with *LangGraph*. Contains many good *examples*
    - https://langchain-ai.github.io/langgraph/tutorials/workflows/
2. Agent examples by Anthropic
    - https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents
3. Nanochat - Building an LLM from scratch with Andrej Karpathy
    - https://github.com/karpathy/nanochat

### Articles
1. Building effective agents - Anthropic
    - Very good article on agentic systems
    - https://www.anthropic.com/engineering/building-effective-agents
2. Introduction to Llama.cpp
    - In depth content with examples
    - https://blog.steelph0enix.dev/posts/llama-cpp-guide/

### Papers
1. ReAct: Synergizing Reasoning and Acting in Language Models
    - Powerful idea for building agents
    - https://arxiv.org/abs/2210.03629
2. Agentic Misalignment: How LLMs Could Be Insider Threats
    - https://arxiv.org/abs/2510.05179
    - https://www.alignmentforum.org/posts/b8eeCGe3FWzHKbePF/agentic-misalignment-how-llms-could-be-insider-threats-1
    - https://github.com/anthropic-experimental/agentic-misalignment
    - Responsible AI problem
